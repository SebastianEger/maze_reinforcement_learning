(dp0
S'learn_rate'
p1
F0.9
sS'tau'
p2
F0.4
sS'weighting'
p3
S'Learn From All'
p4
sS'iterations'
p5
S'100'
p6
sS'use_shared_Q'
p7
I0
sS'action_selection'
p8
S'Greedy'
p9
sS'exploration_rate'
p10
F0.1
sS'cooperation_time'
p11
F5.0
sS'maze'
p12
S'Static maze 1'
p13
sS'cooperation_type'
p14
S'Trials'
p15
sS'reward_goal'
p16
F1000.0
sS'repetitions'
p17
I1
sS'mov'
p18
S'North East South West'
p19
sS'use_reward_matrix'
p20
I0
sS'discount'
p21
F1.0
sS'exploration_type'
p22
S'Constant'
p23
sS'expertness'
p24
S'Normal'
p25
sS'number_agents'
p26
I9
sS'agent_speed'
p27
S'All Equal'
p28
sS'reward_step'
p29
F-0.1
sS'exp'
p30
S'Random'
p31
sS'max_steps'
p32
I50000
sS'reward_wall'
p33
F-10.0
s.